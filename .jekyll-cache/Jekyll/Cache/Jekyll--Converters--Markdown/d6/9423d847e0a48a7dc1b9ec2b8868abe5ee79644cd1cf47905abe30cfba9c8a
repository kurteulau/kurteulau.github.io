I"Q<h2 id="technologiesskills-used">Technologies/Skills Used</h2>
<ul>
  <li><a href="https://spark.apache.org">Spark (Python)</a></li>
  <li><a href="https://spark.apache.org/docs/latest/ml-guide.html">MLlib</a></li>
  <li><a href="https://databricks.github.io/spark-deep-learning/_modules/sparkdl/xgboost/xgboost.html">Spark DL XGBoost</a></li>
  <li><a href="https://www.databricks.com">Databricks</a></li>
  <li><a href="https://docs.databricks.com/delta/index.html">Parquet/Delta Lake data structures</a></li>
  <li><a href="https://www.atlassian.com/software/jira">Jira</a></li>
</ul>

<p><br /></p>

<h2 id="problem-description">Problem Description</h2>
<p>English language learners require timely and accurate feedback on essays in order to measure progress towards fluency. Ideally, students receive constructive feedback indicating which particular areas require greater focus. Manually grading essays with comprehensive rubrics with multiple traits, however, is a laborious process that prevents timely evaluation and is subject to bias and grader fatigue.</p>

<h2 id="data-pipeline">Data Pipeline</h2>
<p>Several foundations, in conjunction with Vanderbilt University and the educational non-profit The Learning Agency Lab, published the ELLIPSE dataset via Kaggle in 2022. Students wrote argumentative essays in response to a variety of different prompts, setting up a cross-prompt multi-trait AES scoring task. According to the Learning Agency Lab, the ELLIPSE corpus ‚Äúcomprises 3911 argumentative essays written by 8th-12th grade ELLs. The essays were scored according to six analytic measures: cohesion, syntax, vocabulary, phraseology, grammar, and conventions‚Ä¶each measure represents a component of proficiency in essay writing, with greater scores corresponding to greater proficiency in that measure. The scores range from 1.0 to 5.0 in increments of 0.5‚Äù</p>

<h2 id="experiments">Experiments</h2>
<p>After preprocessing our text inputs and selecting a performance metric, we developed three families of models:</p>

<p>Baseline experiments that relied on handcrafted features similar to the approach taken by Uto 2020.
The most performant BERT and DeBERTa models that were fine-tuned for our particular task.
Additional BERT and DeBERTa models that were used to illustrate alternative approaches.</p>

<p>A table of the baseline models, subsequent transformer-based models, and accompanying MCRMSE for the final, held-out test sets run with the same number of epochs and batch size follow below. All DeBERTa models employed DeBERTaV3</p>

<h2 id="results">Results</h2>
<p>After preprocessing and modeling, our Spark DL XGBoost algorithm to achieved a RMSE of about 33 minutes. Flight delays had a long right tail. For instance, flight records show a median of -1 minute (a 1 minute early departure) but an average of about 10 minutes late. As evidenced, by the residuals plot below, we struggled with the numerous flights that had extreme departure delays.</p>

<p><br />
<img src="/img/posts/aes_experiments.png" alt="experiments" style="display:block; margin-left:auto; margin-right: auto; width: 60%;" /></p>

<p>Next steps include deeper error analysis into flights with large departure delays, more extensive hyperparameter tuning, an improved PageRank feature (which we used by was not favored by the model), and finally a new pipeline with a multitask loss function to marry the benefits of a neural network classifer alongaside the boosted regression trees provided by XGBoost.</p>

<p>Photo credits:</p>
<ul>
  <li>Banner: https://www.traveldailymedia.com/chicago-ohare-airport-begins-usd-334-million-runway-extension/</li>
</ul>
:ET